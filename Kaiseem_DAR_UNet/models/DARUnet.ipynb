{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33720546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ZPool(nn.Module):\n",
    "    def __init__(self, dim: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([x.max(self.dim, keepdim=True).values, x.mean(self.dim, keepdim=True)], dim=self.dim)\n",
    "\n",
    "class DimAttention(nn.Module):\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.compress = nn.Sequential(\n",
    "            ZPool(dim=1),\n",
    "            nn.Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False),\n",
    "            nn.BatchNorm3d(1, eps=1e-5, momentum=0.01),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.dim != 1:\n",
    "            x = x.transpose(self.dim, 1).contiguous()\n",
    "        out = x * self.compress(x)\n",
    "        if self.dim != 1:\n",
    "            out = out.transpose(self.dim, 1).contiguous()\n",
    "        return out\n",
    "\n",
    "class QAM(nn.Module):\n",
    "    def __init__(self,dims=[1,2,3,4]) -> None:\n",
    "        super().__init__()\n",
    "        self.dims=dims\n",
    "        self.branchs=nn.ModuleList()\n",
    "        for d in dims:\n",
    "            self.branchs.append(DimAttention(dim=d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y=0\n",
    "        for b in self.branchs:\n",
    "            y+=b(x)\n",
    "        y/=len(self.dims)\n",
    "        return y\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, stride=1, anisotropy_stride=False, from_image=False, anisotropy_dim=0):\n",
    "        super(ResBlock, self).__init__()\n",
    "        stride=[stride,stride,stride]\n",
    "\n",
    "        if anisotropy_stride:\n",
    "            stride[anisotropy_dim]=1\n",
    "\n",
    "        if from_image:\n",
    "            self.conv_block = nn.Sequential(\n",
    "                nn.Conv3d(input_dim, output_dim, kernel_size=(3, 3, 3), stride=stride, padding=(1, 1, 1)),\n",
    "                nn.GroupNorm(output_dim // 8, output_dim, affine=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv3d(output_dim, output_dim, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "                nn.GroupNorm(output_dim // 8, output_dim, affine=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv3d(output_dim, output_dim, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            )\n",
    "        else:\n",
    "            self.conv_block = nn.Sequential(\n",
    "                nn.GroupNorm(input_dim // 8, input_dim, affine=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv3d(input_dim, output_dim, kernel_size=(3, 3, 3), stride=stride, padding=(1, 1, 1)),\n",
    "\n",
    "                nn.GroupNorm(output_dim // 8, output_dim, affine=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv3d(output_dim, output_dim, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "\n",
    "                nn.GroupNorm(output_dim // 8, output_dim, affine=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv3d(output_dim, output_dim, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            )\n",
    "\n",
    "        self.conv_skip = nn.Sequential(\n",
    "            nn.Conv3d(input_dim, output_dim, kernel_size=(3, 3, 3), stride=stride, padding=(1, 1, 1)),\n",
    "            nn.GroupNorm(output_dim // 8, output_dim, affine=True),\n",
    "        )\n",
    "\n",
    "        self.qam=QAM()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.qam(self.conv_block(x) + self.conv_skip(x))\n",
    "\n",
    "class VAM(nn.Module):\n",
    "    def __init__(self, encoder_dim, decoder_dim, output_dim, anisotropy_stride=False,anisotropy_dim=0):\n",
    "        super(VAM, self).__init__()\n",
    "        stride = [2, 2, 2]\n",
    "        padding= [1,1,1]\n",
    "        if anisotropy_stride:\n",
    "            stride[anisotropy_dim]=1\n",
    "            padding[anisotropy_dim]=0\n",
    "\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            nn.GroupNorm(encoder_dim//8,encoder_dim,affine=True),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv3d(encoder_dim, output_dim, 3, padding=1),\n",
    "            nn.MaxPool3d(stride,stride),\n",
    "        )\n",
    "\n",
    "        self.conv_decoder = nn.Sequential(\n",
    "            nn.GroupNorm(decoder_dim//8,decoder_dim,affine=True),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv3d(decoder_dim, output_dim, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.conv_attn = nn.Sequential(\n",
    "            nn.GroupNorm(output_dim//8, output_dim,affine=True),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv3d(output_dim, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.upsample = nn.ConvTranspose3d(output_dim,output_dim, kernel_size=3, stride=stride, padding=1, output_padding=padding)\n",
    "\n",
    "    def forward(self, x_e, x_d):\n",
    "        out = self.conv_encoder(x_e) + self.conv_decoder(x_d)\n",
    "        out = self.conv_attn(out)\n",
    "        out = out * x_d\n",
    "        out=self.upsample(out)\n",
    "        return torch.cat([out,x_e],1)\n",
    "\n",
    "def _upsample_like(src,tar):\n",
    "    src = F.upsample(src,size=tar.shape[2:] ,mode='trilinear', align_corners=False)\n",
    "    return src\n",
    "\n",
    "class DARUnet(nn.Module):\n",
    "    def __init__(self,num_classes=3):\n",
    "        super(DARUnet, self).__init__()\n",
    "        channels=[16,32,64,128,256]\n",
    "\n",
    "        self.L1_fromimg = ResBlock(1,channels[0],stride=1,from_image=True)\n",
    "        self.L2_down = ResBlock(channels[0], channels[1], stride=2, anisotropy_stride=True)\n",
    "        self.L3_down = ResBlock(channels[1], channels[2], stride=2, anisotropy_stride=True)\n",
    "        self.L4_down = ResBlock(channels[2], channels[3], stride=2)\n",
    "        self.L5_down = ResBlock(channels[3], channels[4], stride=2)\n",
    "\n",
    "        self.vam4=VAM(channels[3], channels[4], channels[4])\n",
    "        self.L4_up=ResBlock(channels[3] + channels[4], channels[3])\n",
    "\n",
    "        self.vam3 = VAM(channels[2], channels[3], channels[3])\n",
    "        self.L3_up = ResBlock(channels[2] + channels[3], channels[2])\n",
    "\n",
    "        self.vam2 = VAM(channels[1], channels[2], channels[2], anisotropy_stride=True)\n",
    "        self.L2_up = ResBlock(channels[1] + channels[2], channels[1] ,anisotropy_stride=True)\n",
    "\n",
    "        self.vam1 = VAM(channels[0], channels[1], channels[1], anisotropy_stride=True)\n",
    "        self.L1_up = ResBlock(channels[0] + channels[1], channels[0], anisotropy_stride=True)\n",
    "\n",
    "        self.sides=nn.ModuleList([nn.Conv3d(channels[0],num_classes,3,1,1),\n",
    "                                  nn.Conv3d(channels[1], num_classes, 3, 1, 1),\n",
    "                                  nn.Conv3d(channels[2], num_classes, 3, 1, 1),\n",
    "                                  nn.Conv3d(channels[3], num_classes, 3, 1, 1),\n",
    "                                  nn.Conv3d(channels[4], num_classes, 3, 1, 1),\n",
    "        ])\n",
    "\n",
    "        self.outconv = nn.Conv3d(num_classes*5, num_classes, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0 = self.L1_fromimg(x)\n",
    "        x1_0 = self.L2_down(x0_0)\n",
    "        x2_0 = self.L3_down(x1_0)\n",
    "        x3_0 = self.L4_down(x2_0)\n",
    "        x4_1 = self.L5_down(x3_0)\n",
    "\n",
    "        x3_2=self.L4_up(self.vam4(x3_0, x4_1))\n",
    "        x2_3=self.L3_up(self.vam3(x2_0, x3_2))\n",
    "        x1_4=self.L2_up(self.vam2(x1_0,x2_3))\n",
    "        x0_5=self.L1_up(self.vam1(x0_0,x1_4))\n",
    "\n",
    "        d1= self.sides[0](x0_5)\n",
    "        d2= self.sides[1](x1_4)\n",
    "        d3= self.sides[2](x2_3)\n",
    "        d4= self.sides[3](x3_2)\n",
    "        d5= self.sides[4](x4_1)\n",
    "\n",
    "        d2 = _upsample_like(d2,d1)\n",
    "        d3 = _upsample_like(d3,d1)\n",
    "        d4 = _upsample_like(d4,d1)\n",
    "        d5 = _upsample_like(d5,d1)\n",
    "        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5), 1))\n",
    "        return d0,d1,d2,d3,d4,d5\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    model=DARUnet().cuda()\n",
    "    input=torch.rand((2,1,32,256,256)).cuda()\n",
    "    print(model(input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
