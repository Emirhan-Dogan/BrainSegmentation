{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from i2i_solver import i2iSolver\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--ckpt_path', type=str, default='test/i2i_checkpoints/enc_0040.pt')\n",
    "parser.add_argument('--source_npy_dirpath', type=str, default='datasets/source_training_npy')\n",
    "parser.add_argument('--target_npy_dirpath', type=str, default='datasets/target_training_npy')\n",
    "parser.add_argument('--save_npy_dirpath', type=str, default='datasets/source2target_training_npy')\n",
    "parser.add_argument('--k_means_clusters', type=int, default=6)\n",
    "\n",
    "opts = parser.parse_args()\n",
    "trainer=i2iSolver(None)\n",
    "state_dict = torch.load(opts.ckpt_path)\n",
    "trainer.enc_c.load_state_dict(state_dict['enc_c'])\n",
    "trainer.enc_s_a.load_state_dict(state_dict['enc_s_a'])\n",
    "trainer.enc_s_b.load_state_dict(state_dict['enc_s_b'])\n",
    "trainer.dec.load_state_dict(state_dict['dec'])\n",
    "trainer.cuda()\n",
    "\n",
    "styles=[]\n",
    "for f2 in os.listdir(opts.target_npy_dirpath):\n",
    "    if 'label' not in f2:\n",
    "        imgs = np.load(os.path.join(opts.target_npy_dirpath, f2))\n",
    "        for i in range(int(imgs.shape[-1]/6),int(imgs.shape[-1]/6*5)):\n",
    "            img = imgs[:, :, i]\n",
    "            with torch.no_grad():\n",
    "                single_img = torch.from_numpy((img * 2 - 1)).unsqueeze(0).unsqueeze(0).cuda().float()\n",
    "                s=trainer.enc_s_b(single_img).cpu().numpy()[0]\n",
    "                styles.append(s)\n",
    "n_clusters=opts.k_means_clusters\n",
    "k_mean_results = KMeans(n_clusters=opts.k_means_clusters, random_state=9).fit_predict(styles)\n",
    "\n",
    "for f in os.listdir(opts.source_npy_dirpath):\n",
    "    imgs = np.load(os.path.join(opts.source_npy_dirpath, f))\n",
    "    for k in range(n_clusters):\n",
    "        nimgs = np.zeros_like(imgs, dtype=np.float32)\n",
    "        idx=random.choice(np.argwhere(k_mean_results==k).flatten().tolist())\n",
    "        s = torch.from_numpy(styles[idx]).unsqueeze(0).cuda().float()\n",
    "        for i in range(imgs.shape[-1]):\n",
    "            img = imgs[:, :, i]\n",
    "            single_img = torch.from_numpy((img * 2 - 1)).unsqueeze(0).unsqueeze(0).cuda().float()\n",
    "            transfered_img = trainer.inference(single_img, s)\n",
    "            transfered_img = (((transfered_img + 1) / 2).cpu().numpy()).astype(np.float32)[0, 0]\n",
    "            nimgs[:, :, i] = transfered_img\n",
    "        nlabels = np.load(os.path.join('datasets\\source_training_npy', f.replace('img', 'label')))\n",
    "        np.save(os.path.join('datasets\\source2target_training_npy', f.replace('img', f'{k}_img')), nimgs)\n",
    "        np.save(os.path.join('datasets\\source2target_training_npy', f.replace('img', f'{k}_label')), nlabels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
